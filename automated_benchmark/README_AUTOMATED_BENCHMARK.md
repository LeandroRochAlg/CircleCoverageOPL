# ğŸ¤– Sistema de Benchmark Automatizado

Sistema completo para teste automatizado e contÃ­nuo de algoritmos de cobertura de cÃ­rculos.

## ğŸ“š DocumentaÃ§Ã£o

- **[QUICKSTART.md](QUICKSTART.md)** - Guia rÃ¡pido de inÃ­cio (COMECE AQUI!)
- **[BENCHMARK_README.md](BENCHMARK_README.md)** - DocumentaÃ§Ã£o completa e detalhada
- **[TROUBLESHOOTING.md](TROUBLESHOOTING.md)** - SoluÃ§Ãµes para problemas comuns

## ğŸš€ InÃ­cio RÃ¡pido (3 Passos)

### 1ï¸âƒ£ Setup
```powershell
python setup_benchmark.py
```

### 2ï¸âƒ£ Executar
```powershell
python automated_benchmark.py
```

### 3ï¸âƒ£ Analisar
```powershell
python analyze_results.py
```

**OU use o menu interativo:**
```powershell
.\benchmark_menu.bat
```

## ğŸ“¦ Arquivos IncluÃ­dos

### Scripts Principais
- **`automated_benchmark.py`** - Motor principal do benchmark (execuÃ§Ã£o contÃ­nua)
- **`setup_benchmark.py`** - Script de configuraÃ§Ã£o inicial
- **`monitor_benchmark.py`** - Monitor de progresso em tempo real
- **`analyze_results.py`** - AnÃ¡lise estatÃ­stica dos resultados
- **`test_system.py`** - Teste de verificaÃ§Ã£o do sistema

### Scripts Auxiliares
- **`benchmark_menu.bat`** - Menu interativo no Windows
- **`circle_data_generator.py`** - Gerador de dados (legado, integrado no main)
- **`circle_visualizer.py`** - Visualizador de resultados (legado)

### DocumentaÃ§Ã£o
- **`QUICKSTART.md`** - Guia de inÃ­cio rÃ¡pido
- **`BENCHMARK_README.md`** - DocumentaÃ§Ã£o completa
- **`TROUBLESHOOTING.md`** - SoluÃ§Ãµes de problemas

## âš™ï¸ ConfiguraÃ§Ãµes PadrÃ£o

| ParÃ¢metro | Valor | DescriÃ§Ã£o |
|-----------|-------|-----------|
| Tempo limite teÃ³rico | 1 hora | Configurado no CPLEX |
| Timeout real (kill) | 1h10min | ForÃ§a parada apÃ³s este tempo |
| MÃ¡ximo de pontos (n) | 200 | Tamanho mÃ¡ximo da instÃ¢ncia |
| Range minCoverage | 1-5 | Cobertura mÃ­nima aleatÃ³ria |
| ConfiguraÃ§Ãµes testadas | 6 | Teste1 atÃ© Teste6 |

## ğŸ“Š Estrutura de Resultados

```
tests/
â””â”€â”€ automated_results/
    â”œâ”€â”€ results_table.csv              # Tabela consolidada
    â”œâ”€â”€ analysis_summary.json          # Resumo estatÃ­stico
    â”œâ”€â”€ result_Test_0001_Teste1_*.txt  # Resultados individuais
    â”œâ”€â”€ result_Test_0001_Teste2_*.txt
    â””â”€â”€ ...
```

## ğŸ¯ Funcionalidades

### âœ… GeraÃ§Ã£o AutomÃ¡tica de Dados
- DistribuiÃ§Ã£o normal concentrada
- ParÃ¢metros calculados automaticamente
- N entre 5 e 200 pontos
- MinCoverage entre 1 e 5

### âœ… ExecuÃ§Ã£o Automatizada
- Loop infinito atÃ© interrupÃ§Ã£o manual
- 6 configuraÃ§Ãµes testadas sequencialmente
- Timeout rigoroso (1h10min)
- Kill forÃ§ado de processos travados

### âœ… Controle de Recursos
- Tenta reservar 1 nÃºcleo da CPU (requer psutil)
- Gerenciamento de memÃ³ria
- Cleanup automÃ¡tico de processos

### âœ… Registro Completo
- CSV com todos os resultados
- Arquivos individuais por teste
- Timestamps e metadados
- JSON para anÃ¡lise programÃ¡tica

### âœ… Monitoramento em Tempo Real
- AtualizaÃ§Ã£o a cada 10 segundos
- EstatÃ­sticas por configuraÃ§Ã£o
- Taxa de sucesso e tempos mÃ©dios
- Sem interferÃªncia na execuÃ§Ã£o

### âœ… AnÃ¡lise EstatÃ­stica
- EstatÃ­sticas descritivas completas
- ComparaÃ§Ã£o entre configuraÃ§Ãµes
- AnÃ¡lise por tamanho de instÃ¢ncia
- IdentificaÃ§Ã£o de melhores/piores casos

## ğŸ”§ Requisitos

### ObrigatÃ³rio
- Python 3.6+
- NumPy
- IBM ILOG CPLEX Optimization Studio

### Opcional
- psutil (para afinidade de CPU)

### InstalaÃ§Ã£o
```powershell
pip install numpy psutil
```

## ğŸ“ˆ Exemplo de Uso TÃ­pico

```powershell
# Terminal 1: Executar benchmark
python automated_benchmark.py

# Terminal 2: Monitorar progresso
python monitor_benchmark.py

# ApÃ³s algumas horas, analisar resultados
python analyze_results.py
```

## ğŸ¬ Fluxo de ExecuÃ§Ã£o

```
InÃ­cio
  â†“
Gerar Dados AleatÃ³rios (n, r, minCoverage, etc.)
  â†“
Escrever circle_coverage.dat
  â†“
Para cada configuraÃ§Ã£o (Teste1 atÃ© Teste6):
  â†“
  Executar com oplrun (timeout 1h10min)
  â†“
  Extrair resultados (num cÃ­rculos, tempo)
  â†“
  Salvar resultado individual
  â†“
Atualizar results_table.csv
  â†“
Aguardar 10 segundos
  â†“
Repetir (loop infinito atÃ© Ctrl+C)
```

## ğŸ“± Interface do Menu

```
1. Setup inicial (instalar dependÃªncias)
2. Iniciar benchmark (execuÃ§Ã£o contÃ­nua)
3. Monitorar progresso (em tempo real)
4. Analisar resultados
5. Ver Ãºltimos resultados
6. Abrir pasta de resultados
7. Sair
```

## ğŸ” DiagnÃ³stico e Teste

Execute o teste de sistema antes de rodadas longas:
```powershell
python test_system.py
```

Verifica:
- âœ“ Bibliotecas instaladas
- âœ“ OPLRUN acessÃ­vel
- âœ“ Arquivos do projeto
- âœ“ GeraÃ§Ã£o de dados
- âœ“ ExecuÃ§Ã£o bÃ¡sica

## ğŸ’¡ Dicas de Uso

1. **Primeira vez:** Execute `test_system.py` para verificar tudo
2. **Overnight:** Deixe rodando durante a noite para acumular resultados
3. **Monitoramento:** Use terminal separado para monitor
4. **Backup:** FaÃ§a backup periÃ³dico de `automated_results/`
5. **AnÃ¡lise:** Analise resultados periodicamente para detectar padrÃµes

## âš ï¸ ObservaÃ§Ãµes Importantes

- âš ï¸ O arquivo `circle_coverage.dat` Ã© sobrescrito a cada teste
- âš ï¸ Feche o CPLEX IDE durante a execuÃ§Ã£o
- âš ï¸ NÃ£o execute mÃºltiplas instÃ¢ncias simultaneamente
- âš ï¸ Cada rodada completa pode levar atÃ© ~7 horas
- âš ï¸ Resultados "Sem resultado" indicam timeout

## ğŸ› Problemas Comuns

| Problema | SoluÃ§Ã£o RÃ¡pida |
|----------|----------------|
| Module not found | `pip install numpy psutil` |
| oplrun nÃ£o encontrado | Ajustar OPLRUN_PATH |
| Timeout nÃ£o funciona | Executar como Admin |
| CSV vazio | Aguardar teste completar |
| PC lento | Verificar psutil instalado |

Ver [TROUBLESHOOTING.md](TROUBLESHOOTING.md) para detalhes.

## ğŸ“Š Exemplo de SaÃ­da (Monitor)

```
================================================================================
ESTATÃSTICAS DO BENCHMARK
================================================================================
Total de testes executados: 25
Total de execuÃ§Ãµes: 150

Config          Sucessos    Timeouts    Taxa Sucesso    Tempo MÃ©dio     CÃ­rc. MÃ©dio
------------------------------------------------------------------------------------------------
Teste1          18          7           72.0%           845.23s         24.3
Teste2          23          2           92.0%           234.56s         22.1
Teste3          15          10          60.0%           1234.78s        28.7
Teste4          20          5           80.0%           567.89s         23.5
Teste5          22          3           88.0%           345.67s         21.8
Teste6          19          6           76.0%           678.90s         25.2
================================================================================
```

## ğŸ”„ AtualizaÃ§Ãµes e Melhorias

Para ajustar o comportamento do benchmark, edite `automated_benchmark.py`:

```python
# Linha ~18-22
MAX_EXECUTION_TIME = 3600      # Ajustar tempo teÃ³rico
TIMEOUT_KILL = 4200           # Ajustar timeout real
MAX_N = 200                   # Ajustar tamanho mÃ¡ximo
MIN_COVERAGE_RANGE = (1, 5)   # Ajustar range de cobertura
```

## ğŸ“ Suporte

1. Verifique [TROUBLESHOOTING.md](TROUBLESHOOTING.md)
2. Execute `python test_system.py`
3. Revise os logs de execuÃ§Ã£o
4. Verifique arquivos em `automated_results/`

## ğŸ“ Notas de VersÃ£o

**v1.0** (04/11/2025)
- âœ… Sistema completo de benchmark automatizado
- âœ… 6 configuraÃ§Ãµes de teste
- âœ… Monitoramento em tempo real
- âœ… AnÃ¡lise estatÃ­stica
- âœ… DocumentaÃ§Ã£o completa
- âœ… Menu interativo
- âœ… Sistema de troubleshooting

## ğŸ¯ Roadmap Futuro

- [ ] GrÃ¡ficos automÃ¡ticos de comparaÃ§Ã£o
- [ ] ExportaÃ§Ã£o para Excel formatado
- [ ] DetecÃ§Ã£o automÃ¡tica de configuraÃ§Ãµes
- [ ] Interface web para monitoramento
- [ ] NotificaÃ§Ãµes por email ao completar
- [ ] ParalelizaÃ§Ã£o de testes independentes

---

**ğŸš€ Pronto para comeÃ§ar? Leia [QUICKSTART.md](QUICKSTART.md) e execute `python setup_benchmark.py`!**
